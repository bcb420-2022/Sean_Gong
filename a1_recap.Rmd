---
title: "BCB420_A1"
output:
  html_document:
    df_print: paged
---
## Library Preperation

We will start by checking if the required libraries and files are installed.
Then we will load the libraries using library().
```{r message=FALSE, warning=TRUE}
if (!requireNamespace("BiocManager", quietly = TRUE)){
  install.packages("BiocManager")
}
if (!requireNamespace("GEOmetadb", quietly = TRUE)){
  BiocManager::install("GEOmetadb")
}

if (!file.exists('GEOmetadb.sqlite')){
  getSQLiteFile()
}

if (!requireNamespace("biomaRt", quietly = TRUE)){
  BiocManager::install("biomaRt")
}

if (!requireNamespace("edgeR", quietly = TRUE)){
  BiocManager::install("edgeR")
}

library(BiocManager)
library(edgeR)
library(GEOmetadb)
library(biomaRt)
library(knitr)
```

## Data Selection

Now with all libraries installed, we will use the following commands to query the GEOmetadb (GEO database) to look for a dataset with a "raw counts" txt-supplmentary file. Note we are specifically querying datasets with submission dates > 2015-01-01, related to cancer and high throughput sequencing data of Homo sapiens. 
```{r, warning=FALSE, message=FALSE}
sql <- paste("SELECT DISTINCT gse.title,gse.gse, gpl.title,",
             " gse.submission_date,",
             " gse.supplementary_file",
             "FROM",
             "  gse JOIN gse_gpl ON gse_gpl.gse=gse.gse",
             "  JOIN gpl ON gse_gpl.gpl=gpl.gpl",
             "WHERE",
             "  gse.submission_date > '2015-01-01' AND",
             "  gse.title LIKE '%cancer%' AND", 
             "  gpl.organism LIKE '%Homo sapiens%' AND",
             "  gpl.technology LIKE '%high-throughput seq%' ",
             "  ORDER BY gse.submission_date DESC",sep=" ")
con <- dbConnect(SQLite(), 'GEOmetadb.sqlite')
rs <- dbGetQuery(con, sql)
unlist(lapply(rs$supplementary_file,
              FUN = function(x){x <- unlist(strsplit(x,";")) ;
              x <- x[grep(x,pattern="txt",ignore.case = TRUE)];
              tail(unlist(strsplit(x,"/")),n=1)})) [1:30]
```

The chosen dataset is "GSE164531" which is an RNA-seq dataset using the Illumina Hiseq 2000 platform for identification of NEDD9 regulated genes in VCaP prosatate cancer cells. We download the counts data using the following commands and check the dimensions of the data.
```{r include=FALSE, warning=FALSE, message=FALSE}
sfiles <- getGEOSuppFiles('GSE164531')
fnames <- rownames(sfiles)
```

We then load the counts data into R and check the dimensions.
```{r, warning=FALSE, message=FALSE}
data <- read.delim(fnames[1], header = TRUE, check.names = FALSE)
dim(data)
```

Then we quickly check the head of the data (first 10 rows) to explore further.
```{r, warning=FALSE, message=FALSE}
kable(head(data), format = 'html', caption = "Table 0.1: GSE164531 Dataset")
```

## Initial Exploratory Analysis

### Duplicate Genes

The first exploratory analysis is checking for duplicate genes in our data. We run the following commands and find that there are no duplicate genes present in the data. Resulting in no further actions required to deal with duplicate genes.

```{r, warning=FALSE, message=FALSE}
summarized_gene_counts <- sort(table(data$EnsemblID),decreasing = TRUE)
kable(summarized_gene_counts[which(summarized_gene_counts > 1)[1:10]], format = 'html', caption = "Table 0.2: Duplicate genes and it's frequencies")
```

### Missing Data

Now we check for any missing data in the dataset. 

```{r, warning=FALSE, message=FALSE}
# Check which rows have missing data
which(!complete.cases(data))
```

We see that row 58736 has missing data, we access this row to explore further.

```{r, warning=FALSE, message=FALSE}
data[58736,]
```
Seems like this row is just an empty row with no meaningful data. As it contains no data, we can safely remove the row without affecting the data-set (We remove the row as it N/A values may interfere with next steps such as normalization).
```{r, warning=FALSE, message=FALSE}
data <- data[complete.cases(data),]
dim(data)
```

### Grouping the Data
We will define groups for the data according to each biological condition (experiment design) for later steps such as normalization.
```{r, warning=FALSE, message=FALSE}
samples <- data.frame(lapply(colnames(data)[3:8], FUN=function(x){unlist(strsplit(x, split = "_"))[c(1, 2)]}))
colnames(samples) <- colnames(data)[3:8]
rownames(samples) <- c("condition", "replicate")
samples <- data.frame(t(samples))
samples
```

## Filtering Data
We now filter out low counts from the data according to the edgeR protocol. The threshold is set to 3 because edgeR recommends the threshold to be the number of replications which in our data set is 3 (Would be interesting to see what happens if we change our threshold, but we will keep it to 3 for now).
```{r, warning=FALSE, message=FALSE}
cpms <- edgeR::cpm(data[, 3:8])
rownames(cpms) <- data[, 1]
# Threshold set to 3 as recommended by edgeR protocol
keep <- rowSums(cpms > 1) >= 3
dataFiltered <- data[keep, ]
head(dataFiltered)
```

We quickly compare the dimensions of the filtered data and original data.
```{r, warning=FALSE, message=FALSE}
dim(data)
```

```{r, warning=FALSE, message=FALSE}
kable(head(dataFiltered), format = 'html', caption = "Table 0.3: Filtered Data")
```
We notice that the total number of genes reduced to 14682 from 58735 after filtering out low expression data using the edgeR filtering protocol.


## Mapping Data

Now we will map the filtered data to HUGO gene symbols using grch38.p13 and the biomaRt package. The following commands creates a ensembl_gene_id and HUGO gene symbol conversion table which we will use to merge with the expression data after normalization.
```{r, warning=FALSE, message=FALSE}
ensembl <- useEnsembl("ensembl")
ensembl <- useDataset("hsapiens_gene_ensembl",mart=ensembl)
conversionStash <- "data_conversion.rds"
if(file.exists(conversionStash)){
  dataIdConversion <- readRDS(conversionStash)
} else {
  dataIdConversion <- getBM(attributes = c("ensembl_gene_id", "hgnc_symbol"),
                               filters = c("ensembl_gene_id"),
                               values = dataFiltered$EnsemblID,
                               mart = ensembl)
  saveRDS(dataIdConversion, conversionStash)
}

kable(head(dataIdConversion), format = 'html', caption = "Table 0.4: Ensembl Gene Id to hgnc symbol")
```

## Normalization

We will now normalize our data using the TMM method using the following commands.
```{r, warning=FALSE, message=FALSE}
filteredDataMatrix <- as.matrix(dataFiltered[,3:8])
rownames(filteredDataMatrix) <- dataFiltered$EnsemblID
d = DGEList(counts = filteredDataMatrix, group = samples$condition)
d = calcNormFactors(d)
normalizedCounts <- cpm(d)
```

Now we will merge the normalizedCounts with our identifiers that we mapped in our previous step. Now we have a dataFrame with mapped ensembl_gene_id, HUGO gene symbols and normalized expression data.

```{r, warning=FALSE, message=FALSE}
dataFilteredAnnot <- merge(dataIdConversion, normalizedCounts, by.x = 1, by.y = 0, all.y=TRUE)
kable(dataFilteredAnnot[1:5,1:8],type = "html", caption = "Table 0.5: Normalized Data")
```


### Pre-normalization Density vs Post-normalization Density
The density plots for pre-normalization and post-normalization data is plotted for comparison.

#### Pre-normalization:
```{r, warning=FALSE, message=FALSE, fig.cap= "Fig. 0.1: Density Plot for Pre-normalization data"}
pre_data2plot <- log2(cpm(dataFiltered[, 3:8]))
pre_counts_density <- apply(log2(cpm(dataFiltered[, 3:8])), 2, density)
xlim <- 0
ylim <- 0
for (i in 1:length(pre_counts_density)) {
  xlim <- range(c(xlim, pre_counts_density[[i]]$x)); 
  ylim <- range(c(ylim, pre_counts_density[[i]]$y))
  }
cols <- rainbow(length(pre_counts_density))
ltys <- rep(1, length(pre_counts_density))
#plot the first density plot to initialize the plot
plot(pre_counts_density[[1]], xlim=xlim, ylim=ylim, type="n", ylab="Smoothing density of log2-CPM", main="", cex.lab = 0.85)
#plot each line
for (i in 1:length(pre_counts_density)) lines(pre_counts_density[[i]], col=cols[i], lty=ltys[i])
#create legend
legend("topright", colnames(pre_data2plot),  
       col=cols, lty=ltys, cex=0.75,
       border ="blue",  text.col = "green4",
       merge = TRUE, bg = "gray90")
```

<br>

#### Post-normalization:
```{r, warning=FALSE, message=FALSE, fig.cap = "Fig. 0.2: Density Plot for Post-normalization data"}
post_data2plot <- log2(cpm(dataFilteredAnnot[, 3:8]))
post_counts_density <- apply(log2(cpm(dataFilteredAnnot[, 3:8])), 2, density)
xlim <- 0
ylim <- 0
for (i in 1:length(post_counts_density)) {
  xlim <- range(c(xlim, post_counts_density[[i]]$x)) 
  ylim <- range(c(ylim, post_counts_density[[i]]$y))
  }
cols <- rainbow(length(post_counts_density))
ltys <- rep(1, length(post_counts_density))
#plot the first density plot to initialize the plot
plot(post_counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
ylab="Smoothing density of log2-CPM", main="", cex.lab = 0.85)
#plot each line
for (i in 1:length(post_counts_density)) lines(post_counts_density[[i]], col=cols[i], lty=ltys[i])
#create legend
legend("topright", colnames(post_data2plot),  
       col=cols, lty=ltys, cex=0.75, 
       border ="blue",  text.col = "green4", 
       merge = TRUE, bg = "gray90")
```

<br>
Notice no significance difference between pre and post normalization. I believe this is due to the fact that my original data happens to be close to a normal distribution, thus normalization with TMM method did not make any significant changes.

## Missing Identifiers

We will now deal with missing identifiers (missing HUGO gene symbols). First, we will check how many missing identifiers are present in our data right now.

```{r, warning=FALSE, message=FALSE}
ensembl_id_missing_gene <- dataFilteredAnnot$ensembl_gene_id[which((dataFilteredAnnot$hgnc_symbol) == "")]
length(ensembl_id_missing_gene)
```
We see that we have 732 missing identifiers, lets check out some of these rows with missing identifiers.
```{r, warning=FALSE, message=FALSE}
kable(dataFilteredAnnot[which((dataFilteredAnnot$hgnc_symbol == ""))[1:5],1:8], type="html", caption = "Table 0.6: Genes with missing identifiers")
```
As the missing identifiers are only ~5% of the data set, we will keep these rows for now and continue with our analysis. Also, we have knowledge of the rows with missing identifiers which will allow us to remove/modify how we handle these missing identifiers easily later on in our analysis and removing these data at this step does not seem the best practice (would be interesting to see how these genes with missing identifiers result in our final analysis).

## Final Data

Now we present the final data set that has been filtered, normalized and mapped to HUGO gene symbols with 14683 genes (rows).
```{r, warning=FALSE, message=FALSE}
kable(head(dataFilteredAnnot), format = "html", caption = "Table 0.7: Final Dataset")
```

```{r, warning=FALSE, message=FALSE}
dim(dataFilteredAnnot)
```
